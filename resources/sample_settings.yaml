project:
  debug: true
  json_serializer: default # or complex. If "complex", FlowCept will deal with complex python dicts that may contain JSON unserializable values
  replace_non_json_serializable: true
  performance_logging: false
  register_workflow: true
  enrich_messages: true

  telemetry_capture:
    gpu: ~
    cpu: true
    per_cpu: true
    process_info: true
    mem: true
    disk: true
    network: true
    machine_info: true

instrumentation:
  torch:
    mode: base   # base, tensor_inspection, with_telemetry, full, ~ #(none)

log:
  log_path: "default"
  log_file_level: error
  log_stream_level: error

experiment:
  user: root
  campaign_id: super_campaign

main_redis:
  host: localhost
  instances: ["localhost:6379"] # We can have multiple redis instances being accessed by the consumers but each interceptor will currently access one single redis.
  port: 6379
  channel: interception
  buffer_size: 50
  insertion_buffer_time_secs: 5

mongodb:
  host: localhost
  port: 27017
  db: flowcept
  collection: tasks
  insertion_buffer_time_secs: 5
  max_buffer_size: 50
  min_buffer_size: 10
  remove_empty_fields: false
  create_collection_index: true

web_server:
  host: 0.0.0.0
  port: 5000

sys_metadata:
  environment_id: "frontier"

extra_metadata:
  place_holder: ""

analytics:
  sort_orders:
    generated.loss: minimum_first
    generated.accuracy: maximum_first


adapters:
  # For each key below, you can have multiple instances. Like mlflow1, mlflow2; zambeze1, zambeze2. Use an empty dict, {}, if you won't use any adapter.
  zambeze:
    kind: zambeze
    host: localhost
    port: 5672
    queue_names:
      - hello
      - hello2
#    key_values_to_filter:
#      - key: activity_status
#        value: CREATED

  mlflow:
    kind: mlflow
    file_path: mlflow.db
    log_params: ['*']
    log_metrics: ['*']
    redis_host: localhost
    redis_port: 6379
    watch_interval_sec: 2

  tensorboard:
    kind: tensorboard
    file_path: tensorboard_events
    log_tags: ['scalars', 'hparams', 'tensors']
    log_metrics: ['accuracy']
    redis_host: localhost
    redis_port: 6379
    watch_interval_sec: 5

  dask:
    kind: dask
    redis_host: localhost
    redis_port: 6379
    worker_should_get_input: true
    scheduler_should_get_input: true
    worker_should_get_output: true
    scheduler_create_timestamps: true
    worker_create_timestamps: false
